Debug with sqlparse


psql -d template1 -U postgres
CREATE DATABASE bioinfo_biobureau;
CREATE USER raony WITH PASSWORD 'raony';
GRANT ALL PRIVILEGES ON DATABASE bioinfo_biobureau to raony;

pip install sqlparse==0.1.19


Tasks

celery -A bioinfo_biobureau.taskapp worker -l info

tasks working!


changed in local.py
to
CELERY_ALWAYS_EAGER = False
instead of true

celery -A bioinfo_biobureau.taskapp worker -l info
python manage.py celery worker -l DEBUG

also working!!

for i in *; do zip $i.zip $i; done

http://stackoverflow.com/questions/29831976/manual-commit-in-django-1-8/29834940

http://stackoverflow.com/questions/29149714/upgrading-transaction-commit-manually-to-django-1-6


[2016-07-28 13:11:28,066: WARNING/Worker-1] alignments/1/Casearia_sylvestris_results.tab.zip
[2016-07-28 13:11:28,406: WARNING/Worker-1] Import FILE
[2016-07-28 13:11:28,406: WARNING/Worker-1] 13
[2016-07-28 13:11:28,404: ERROR/MainProcess] Task import_alignment_to_database[4b2ff504-e02d-4faa-96ed-0f86e88bae32] raised unexpected: IndexError('list index out of range',)
Traceback (most recent call last):
  File "/home/raony/.virtualenvs/bioinfo_biobureau/lib/python3.5/site-packages/celery/app/trace.py", line 240, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/raony/.virtualenvs/bioinfo_biobureau/lib/python3.5/site-packages/celery/app/trace.py", line 438, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/raony/dev/bitbucket/bioinfo_biobureau/projects/tasks.py", line 85, in import_alignment
    aln_hit.RepID = hit[16]
IndexError: list index out of range
[2016-07-28 13:11:28,411: WARNING/Worker-1] alignments/1/Cedrela_fissilis_results.tab.zip
[2016-07-28 13:13:53,381: WARNING/Worker-1] Inserting Final...
[2016-07-28 13:13:54,077: WARNING/Worker-1] Finished!
[2016-07-28 13:13:54,092: WARNING/Worker-1] Import FILE
[2016-07-28 13:13:54,092: WARNING/Worker-1] 14
[2016-07-28 13:13:54,097: WARNING/Worker-1] alignments/1/Centella_asiatica_results.tab.zip
[2016-07-28 13:13:54,155: ERROR/MainProcess] Task import_alignment_to_database[a4b46689-218c-4358-932b-5cbf0575ebfa] raised unexpected: IndexError('list index out of range',)
Traceback (most recent call last):
  File "/home/raony/.virtualenvs/bioinfo_biobureau/lib/python3.5/site-packages/celery/app/trace.py", line 240, in trace_task
    R = retval = fun(*args, **kwargs)
  File "/home/raony/.virtualenvs/bioinfo_biobureau/lib/python3.5/site-packages/celery/app/trace.py", line 438, in __protected_call__
    return self.run(*args, **kwargs)
  File "/home/raony/dev/bitbucket/bioinfo_biobureau/projects/tasks.py", line 85, in import_alignment
    aln_hit.RepID = hit[16]
IndexError: list index out of range


[2016-07-28 13:40:08,703: WARNING/Worker-1] alignments/1/Casearia_sylvestris_results.tab.zip
[2016-07-28 13:40:08,704: WARNING/Worker-1] ['qseqid', 'sseqid', 'pident', 'length', 'mismatch', 'gapopen', 'qstart', 'qend', 'sstart', 'send', 'evalue', 'bitscore', 'GI', 'GeneID', 'NCBI-taxon of the reference', 'Lowest taxon of the cluster', 'RepID', 'Cluster Name\n']
[2016-07-28 13:40:08,704: WARNING/Worker-1] 18
[2016-07-28 13:40:08,704: WARNING/Worker-1] ['0', 'UniRef90_B9HBM9', '94.2', '69', '4', '0', '208', '2', '387', '455', '1.9e-28', '131.7', '566175247; 550335802', '7487261', '3694', 'Populus', 'B9HBM9_POPTR', 'Uncharacterized protein ', 'GO:0003700 GO:0006351\n']
[2016-07-28 13:40:08,705: WARNING/Worker-1] 19
[2016-07-28 13:40:08,714: WARNING/Worker-1] ['1', 'UniRef90_UPI0005FB7953', '61.2', '67', '26', '0', '8', '208', '246', '312', '4.6e-14', '84.0', '', 'Jatropha curcas', 'UPI0005FB7953', 'PREDICTED: uncharacterized protein LOC105640120 \n']
[2016-07-28 13:40:08,715: WARNING/Worker-1] 16









6   UniRef90_A0A024KYX1 100.0   156 0   0   2   469 20  175 1.4e-84 319.7   597601083; 665444161; 597610118; 597618322; 59760...    562 root    A0A024KYX1_ECOLX    Major spike protein G   GO:0019048 GO:0019028 GO:0005198 NA

7   UniRef90_A0A024KYX1 100.0   156 0   0   1   468 20  175 1.4e-84 319.7   597601083; 665444161; 597610118; 597618322; 59760...    562 root    A0A024KYX1_ECOLX    Major spike protein G   GO:0019048 GO:0019028 GO:0005198 NA


S3 boto

Configuring

PlataformaBioinfo
Access Key ID:
AKIAIUIQT7TUOXOQFUPQ
Secret Access Key:
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

us-west-2


https://github.com/boto/boto3

For the pipeline

https://github.com/MikkelSchubert/adapterremoval

boto3 e paramiko

https://aws.amazon.com/blogs/compute/scheduling-ssh-jobs-using-aws-lambda/

http://stackoverflow.com/questions/6025546/issues-trying-to-ssh-into-a-fresh-ec2-instance-with-paramiko

python manage.py startapp analyses



Client Id
1fdcf4268f714b9b97e3ecb68b75be19
Client Secret
6d3db5904e914faa8a2ba7838215400e


Access Token
15a4f67f257f4463bf70c2eec0875a7e

using trsuty is best to install

We are excited to announce BaseMount v0.14 with Trash control.


This update includes:

    Move-to-trash and restore-from-trash
    Refresh command
    New bm-cmd tool, a shorter alias for basemount-cmd
    Moved passphrase encryption to --passphrase

As always, you can install or update BaseMount using the command line:

sudo bash -c "$(curl -L https://basemount.basespace.illumina.com/install)" 

More details can be found on the following pages:

    Blog post
    BaseMount website
    BaseMount help page & documentation

https://basemount.basespace.illumina.com/

copy file from basespace to s3

PlataformaBioinfo
Create a computer to be the worker!
Connect Remotely to database!

psql -p 5432 -h example.cs945smhrv09.us-west-2.rds.amazonaws.com -U example example

Configure /etc/postgresql/9.1/main/pg_hba.conf to allow connection from a domain of VPC
psql -h ec2-xxx-xx-xxx-xxx.compute-1.amazonaws.com -d <database_name> -U <username>  

I Found the resolution to this problem. Two things are required.

    Use a text editor to modify pg_hba.conf. Locate the line host all all 127.0.0.1/0 md5. Immediately below it, add this new line: host all all 0.0.0.0/0 md5

    Editing the PostgreSQL postgresql.conf file:

    Use a text editor to modify postgresql.conf. Locate the line that starts with #listen_addresses = 'localhost'. Uncomment the line by deleting the #, and change localhost to . The line should now look like this: listen_addresses = '' # what IP address(es) to listen on;.

Now Just restart your postgres service and it will connect

Secondary private IPs
  
Scheduled events
No scheduled events
VPC ID
vpc-67cb2e02

Private IPs
172.31.26.40
Public IP
54.173.21.14

GBS_MR3

You are using the following Amazon EC2 resources in the US East (N. Virginia) region:
2 Running Instances
0 Dedicated Hosts
2 Volumes
8 Key Pairs
0 Placement Groups

1 Elastic IPs
8 Snapshots
0 Load Balancers
18 Security Groups

from fabric.api import env, run

env.hosts = ['host1@example.com', 'host2@example.com']

def reload():
    """ Reload Apache """
    run("sudo /etc/init.d/apache2 reload")


http://docs.python-guide.org/en/latest/scenarios/admin/

Add prefixes VR1, VR2 e VR3


createdb: database creation failed: ERROR:  permission denied to create database

sudo -u postgres psql -c "grant all on tablespace pg_default to raony"

sudo -u postgres psql -c "ALTER USER raony CREATEDB"
Worked!


Deploying


sudo apt-get install postgresql python3-dev libpq-dev virtualenvwrapper
source /etc/bash_completion.d/virtualenvwrapper
mkvirtualenv -p /usr/bin/python3 biobureau

cd scripts/basespace/src

python setup.py install
pip install -r requirements.txt 
pip install -r requirements/local.txt 
pip install sqlparse==0.1.19


psql -d template1 -U postgres
CREATE DATABASE bioinfo_biobureau;
CREATE USER raony WITH PASSWORD 'raony';
GRANT ALL PRIVILEGES ON DATABASE bioinfo_biobureau to raony;

python manage.py migrate
python manage.py loaddata fixtures/users.json
python manage.py runserver


AWS S3 keys!

Copy .aws .basespace


['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_id', 'ami_launch_index', 'architecture', 'attach_classic_link_vpc', 'attach_volume', 'block_device_mappings', 'classic_address', 'client_token', 'console_output', 'create_image', 'create_tags', 'delete_tags', 'describe_attribute', 'detach_classic_link_vpc', 'detach_volume', 'ebs_optimized', 'ena_support', 'get_available_subresources', 'hypervisor', 'iam_instance_profile', 'id', 'image', 'image_id', 'instance_id', 'instance_lifecycle', 'instance_type', 'kernel_id', 'key_name', 'key_pair', 'launch_time', 'load', 'meta', 'modify_attribute', 'monitor', 'monitoring', 'network_interfaces', 'network_interfaces_attribute', 'password_data', 'placement', 'placement_group', 'platform', 'private_dns_name', 'private_ip_address', 'product_codes', 'public_dns_name', 'public_ip_address', 'ramdisk_id', 'reboot', 'reload', 'report_status', 'reset_attribute', 'reset_kernel', 'reset_ramdisk', 'reset_source_dest_check', 'root_device_name', 'root_device_type', 'security_groups', 'source_dest_check', 'spot_instance_request_id', 'sriov_net_support', 'start', 'state', 'state_reason', 'state_transition_reason', 'stop', 'subnet', 'subnet_id', 'tags', 'terminate', 'unmonitor', 'virtualization_type', 'volumes', 'vpc', 'vpc_addresses', 'vpc_id', 'wait_until_exists', 'wait_until_running', 'wait_until_stopped', 'wait_until_terminated']

Test connection to new host

['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_id', 'ami_launch_index', 'architecture', 'attach_classic_link_vpc', 'attach_volume', 'block_device_mappings', 'classic_address', 'client_token', 'console_output', 'create_image', 'create_tags', 'delete_tags', 'describe_attribute', 'detach_classic_link_vpc', 'detach_volume', 'ebs_optimized', 'ena_support', 'get_available_subresources', 'hypervisor', 'iam_instance_profile', 'id', 'image', 'image_id', 'instance_id', 'instance_lifecycle', 'instance_type', 'kernel_id', 'key_name', 'key_pair', 'launch_time', 'load', 'meta', 'modify_attribute', 'monitor', 'monitoring', 'network_interfaces', 'network_interfaces_attribute', 'password_data', 'placement', 'placement_group', 'platform', 'private_dns_name', 'private_ip_address', 'product_codes', 'public_dns_name', 'public_ip_address', 'ramdisk_id', 'reboot', 'reload', 'report_status', 'reset_attribute', 'reset_kernel', 'reset_ramdisk', 'reset_source_dest_check', 'root_device_name', 'root_device_type', 'security_groups', 'source_dest_check', 'spot_instance_request_id', 'sriov_net_support', 'start', 'state', 'state_reason', 'state_transition_reason', 'stop', 'subnet', 'subnet_id', 'tags', 'terminate', 'unmonitor', 'virtualization_type', 'volumes', 'vpc', 'vpc_addresses', 'vpc_id', 'wait_until_exists', 'wait_until_running', 'wait_until_stopped', 'wait_until_terminated']


 ssh ubuntu@52.23.175.55

 working!!!
 now try using script


fab sethost:52.23.175.55 initiate_instance

test connections with

ssh ubuntu@54.173.21.14

sudo -u postgres psql -c "grant all on tablespace pg_default to raony"
sudo -u postgres psql -c "ALTER USER raony CREATEDB"
sudo -u postgres psql -c "DROP DATABASE bioinfo_biobureau"


s3cmd

 Config file name. Defaults to $HOME/.s3cfg

s3cmd

/home/raony/.s3cfg

Try to copy one file
s3cmd ls

s3cmd get s3://logix.cz-test/addrbook.xml addressbook-2.xml

s3cmd ls s3://bioinfobiobureau/input/

s3cmd get --progress --continue s3://bioinfobiobureau/input/MRGBS1_S1_L005_R1_001.fastq.gz



Create First Project FUll

ACCGT Solanum_pseudoquina.fastq
CTGAC Inga_edulis.fastq
GATCA Alchornea_sidifolia.fastq
CGATC Achyrocline_alata.fastq
TCGCA Mikania_micrantha.fastq
CGCAT Lantana_trifolia.fastq
TCAGC Piper_gaudichaudianum.fastq
GACTC Baccharis_semiserrata.fastq
AGTCC Hedychium_coronarium.fastq
CTCGA Cedrela_fissilis.fastq
GCACT Piptadenia_gonoacantha.fastq
AGCTA Ocotea_odorifera.fastq
CAGCT Sphagneticola_trilobata.fastq
GCTAC Solanum_swartzianum.fastq
ACGTC Xylopia_brasiliensis.fastq
CATGC Guarea_macrophylla.fastq
ATGCGT Cabralea_canjerana.fastq
TCCAGT Asclepias_curassavica.fastq
GCTTGA Nectandra_leucantha.fastq
CTGGTA Monstera_adansonii.fastq
GTACAT Astrocaryum_aculeatissimum.fastq
CTTAGT Ludwigia_octovalvis.fastq
TCCGTA Bactris_setosa.fastq
TGACCT Maytenus_aquifolia.fastq

AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT
CAAGCAGAAGACGGCATACGAGATCGGTCTCGGCATTCCTGCTGAACCGCTCTTCCGATCT



sudo apt-get install awscli

aws s3 ls bioinfobiobureau/input/

Total FastQ records: 231624922

FastQ records for barcode TGACCT: 5785113
FastQ records for barcode TCCGTA: 19364105
FastQ records for barcode CTTAGT: 16196273
FastQ records for barcode GTACAT: 9275577
FastQ records for barcode CTGGTA: 7522820
FastQ records for barcode GCTTGA: 5200815
FastQ records for barcode TCCAGT: 9224380
FastQ records for barcode ATGCGT: 9207889
FastQ records for barcode CATGC: 20649117
FastQ records for barcode ACGTC: 17213379
FastQ records for barcode GCTAC: 11363509
FastQ records for barcode CAGCT: 3959776
FastQ records for barcode AGCTA: 24561542
FastQ records for barcode GCACT: 2702463
FastQ records for barcode CTCGA: 30427775
FastQ records for barcode AGTCC: 7969264
FastQ records for barcode GACTC: 2575024
FastQ records for barcode TCAGC: 13207804
FastQ records for barcode CGCAT: 64896
FastQ records for barcode TCGCA: 8207716
FastQ records for barcode CGATC: 1344119
FastQ records for barcode GATCA: 219384
FastQ records for barcode CTGAC: 155540
FastQ records for barcode ACCGT: 194035

FastQ records with no barcode match: 5032607

Number of mismatches allowed: 1




http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html

https://aws.amazon.com/ec2/pricing/

Trying a better cpu machine


Model   vCPU  Mem (GiB)   Storage
  Dedicated EBS Bandwidth (Mbps)
c4.large  2   3.75  EBS-Only  500

c4.large $0.105 hourly $75.6 Dollars per month

Model   vCPU  Mem (GiB)   SSD Storage (GB)  Dedicated EBS Bandwidth (Mbps)
m4.large  2  8   EBS-only 450
m4.xlarge   4 16  EBS-only 750
m4.2xlarge  8  32  EBS-only  1,000

m4.large $0.12 per Hour $86.4 per month
m4.xlarge $0.239 per Hour $172.08 per month
m4.2xlarge $0.479 per Hour $344.88 per month

http://www.ec2instances.info/

Run with different parameters on cutadapt
Run assembly

ssh ubuntu@75.101.210.240


http://catchenlab.life.illinois.edu/stacks/comp/process_radtags.php


67M Sep  7 09:27 Solanum_pseudoquina.cutadapt.fastq


